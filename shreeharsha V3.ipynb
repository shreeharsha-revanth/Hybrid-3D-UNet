{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.7.9","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"gpu","dataSources":[{"sourceId":1299795,"sourceType":"datasetVersion","datasetId":751906},{"sourceId":2039896,"sourceType":"datasetVersion","datasetId":1221832},{"sourceId":2089321,"sourceType":"datasetVersion","datasetId":1252728}],"dockerImageVersionId":30068,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"# DEFINE seg-areas  \nSEGMENT_CLASSES = {\n    0 : 'NOT tumor',\n    1 : 'NECROTIC/CORE', # or NON-ENHANCING tumor CORE\n    2 : 'EDEMA',\n    3 : 'ENHANCING' # original 4 -> converted into 3 later\n}\n\n# there are 155 slices per volume\n# to start at 5 and use 145 slices means we will skip the first 5 and last 5 \nVOLUME_SLICES = 100 \nVOLUME_START_AT = 22 # first slice of volume that we will include","metadata":{"execution":{"iopub.status.busy":"2024-07-19T21:58:11.214227Z","iopub.execute_input":"2024-07-19T21:58:11.214585Z","iopub.status.idle":"2024-07-19T21:58:11.2197Z","shell.execute_reply.started":"2024-07-19T21:58:11.214549Z","shell.execute_reply":"2024-07-19T21:58:11.218398Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import os\nimport cv2\nimport glob\nimport PIL\nimport shutil\nimport numpy as np\nimport pandas as pd\nimport seaborn as sns\nimport matplotlib.pyplot as plt\nfrom skimage import data\nfrom skimage.util import montage \nimport skimage.transform as skTrans\nfrom skimage.transform import rotate\nfrom skimage.transform import resize\nfrom PIL import Image, ImageOps  \n\n\n# neural imaging\nimport nilearn as nl\nimport nibabel as nib\nimport nilearn.plotting as nlplt\n!pip install git+https://github.com/miykael/gif_your_nifti # nifti to gif \nimport gif_your_nifti.core as gif2nif\n\n\n# ml libs\nimport keras\nimport keras.backend as K\nfrom keras.callbacks import CSVLogger\nimport tensorflow as tf\nfrom tensorflow.keras.utils import plot_model\nfrom sklearn.preprocessing import MinMaxScaler\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.metrics import classification_report\nfrom tensorflow.keras.models import *\nfrom tensorflow.keras.layers import *\nfrom tensorflow.keras.optimizers import *\nfrom tensorflow.keras.callbacks import ModelCheckpoint, ReduceLROnPlateau, EarlyStopping, TensorBoard\nfrom tensorflow.keras.layers.experimental import preprocessing\n\n\n# Make numpy printouts easier to read.\nnp.set_printoptions(precision=3, suppress=True)","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","_kg_hide-output":true,"execution":{"iopub.status.busy":"2024-07-19T21:57:46.489248Z","iopub.execute_input":"2024-07-19T21:57:46.489732Z","iopub.status.idle":"2024-07-19T21:58:11.211596Z","shell.execute_reply.started":"2024-07-19T21:57:46.489637Z","shell.execute_reply":"2024-07-19T21:58:11.210505Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"TRAIN_DATASET_PATH = '../input/brats20-dataset-training-validation/BraTS2020_TrainingData/MICCAI_BraTS2020_TrainingData/'\nVALIDATION_DATASET_PATH = '../input/brats20-dataset-training-validation/BraTS2020_ValidationData/MICCAI_BraTS2020_ValidationData'\n\ntest_image_flair=nib.load(TRAIN_DATASET_PATH + 'BraTS20_Training_001/BraTS20_Training_001_flair.nii').get_fdata()\ntest_image_t1=nib.load(TRAIN_DATASET_PATH + 'BraTS20_Training_001/BraTS20_Training_001_t1.nii').get_fdata()\ntest_image_t1ce=nib.load(TRAIN_DATASET_PATH + 'BraTS20_Training_001/BraTS20_Training_001_t1ce.nii').get_fdata()\ntest_image_t2=nib.load(TRAIN_DATASET_PATH + 'BraTS20_Training_001/BraTS20_Training_001_t2.nii').get_fdata()\ntest_mask=nib.load(TRAIN_DATASET_PATH + 'BraTS20_Training_001/BraTS20_Training_001_seg.nii').get_fdata()\n\n\nfig, (ax1, ax2, ax3, ax4, ax5) = plt.subplots(1,5, figsize = (20, 10))\nslice_w = 25\nax1.imshow(test_image_flair[:,:,test_image_flair.shape[0]//2-slice_w], cmap = 'gray')\nax1.set_title('Image flair')\nax2.imshow(test_image_t1[:,:,test_image_t1.shape[0]//2-slice_w], cmap = 'gray')\nax2.set_title('Image t1')\nax3.imshow(test_image_t1ce[:,:,test_image_t1ce.shape[0]//2-slice_w], cmap = 'gray')\nax3.set_title('Image t1ce')\nax4.imshow(test_image_t2[:,:,test_image_t2.shape[0]//2-slice_w], cmap = 'gray')\nax4.set_title('Image t2')\nax5.imshow(test_mask[:,:,test_mask.shape[0]//2-slice_w])\nax5.set_title('Mask')\n","metadata":{"_kg_hide-input":true,"execution":{"iopub.status.busy":"2024-07-19T21:58:11.221307Z","iopub.execute_input":"2024-07-19T21:58:11.221683Z","iopub.status.idle":"2024-07-19T21:58:12.76024Z","shell.execute_reply.started":"2024-07-19T21:58:11.221649Z","shell.execute_reply":"2024-07-19T21:58:12.759121Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Skip 50:-50 slices since there is not much to see\nfig, ax1 = plt.subplots(1, 1, figsize = (15,15))\nax1.imshow(rotate(montage(test_image_t1[50:-50,:,:]), 90, resize=True), cmap ='gray')","metadata":{"_kg_hide-input":true,"execution":{"iopub.status.busy":"2024-07-19T21:58:12.761968Z","iopub.execute_input":"2024-07-19T21:58:12.76239Z","iopub.status.idle":"2024-07-19T21:58:13.894623Z","shell.execute_reply.started":"2024-07-19T21:58:12.762341Z","shell.execute_reply":"2024-07-19T21:58:13.89368Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Skip 50:-50 slices since there is not much to see\nfig, ax1 = plt.subplots(1, 1, figsize = (15,15))\nax1.imshow(rotate(montage(test_mask[60:-60,:,:]), 90, resize=True), cmap ='gray')","metadata":{"_kg_hide-input":true,"execution":{"iopub.status.busy":"2024-07-19T21:58:13.897979Z","iopub.execute_input":"2024-07-19T21:58:13.898301Z","iopub.status.idle":"2024-07-19T21:58:14.796796Z","shell.execute_reply.started":"2024-07-19T21:58:13.89827Z","shell.execute_reply":"2024-07-19T21:58:14.795755Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"shutil.copy2(TRAIN_DATASET_PATH + 'BraTS20_Training_001/BraTS20_Training_001_flair.nii', './test_gif_BraTS20_Training_001_flair.nii')\ngif2nif.write_gif_normal('./test_gif_BraTS20_Training_001_flair.nii')","metadata":{"_kg_hide-input":true,"_kg_hide-output":true,"execution":{"iopub.status.busy":"2024-07-19T21:58:14.798846Z","iopub.execute_input":"2024-07-19T21:58:14.799195Z","iopub.status.idle":"2024-07-19T21:58:18.919938Z","shell.execute_reply.started":"2024-07-19T21:58:14.79916Z","shell.execute_reply":"2024-07-19T21:58:18.918958Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"**Gif representation of slices in 3D volume**\n<img src=\"https://media1.tenor.com/images/15427ffc1399afc3334f12fd27549a95/tenor.gif?itemid=20554734\">","metadata":{}},{"cell_type":"markdown","source":"**Show segments of tumor using different effects**","metadata":{}},{"cell_type":"markdown","source":"","metadata":{}},{"cell_type":"code","source":"niimg = nl.image.load_img(TRAIN_DATASET_PATH + 'BraTS20_Training_001/BraTS20_Training_001_flair.nii')\nnimask = nl.image.load_img(TRAIN_DATASET_PATH + 'BraTS20_Training_001/BraTS20_Training_001_seg.nii')\n\nfig, axes = plt.subplots(nrows=4, figsize=(30, 40))\n\n\nnlplt.plot_anat(niimg,\n                title='BraTS20_Training_001_flair.nii plot_anat',\n                axes=axes[0])\n\nnlplt.plot_epi(niimg,\n               title='BraTS20_Training_001_flair.nii plot_epi',\n               axes=axes[1])\n\nnlplt.plot_img(niimg,\n               title='BraTS20_Training_001_flair.nii plot_img',\n               axes=axes[2])\n\nnlplt.plot_roi(nimask, \n               title='BraTS20_Training_001_flair.nii with mask plot_roi',\n               bg_img=niimg, \n               axes=axes[3], cmap='Paired')\n\nplt.show()","metadata":{"_kg_hide-input":true,"execution":{"iopub.status.busy":"2024-07-19T21:58:18.921707Z","iopub.execute_input":"2024-07-19T21:58:18.922146Z","iopub.status.idle":"2024-07-19T21:58:27.104846Z","shell.execute_reply.started":"2024-07-19T21:58:18.922099Z","shell.execute_reply":"2024-07-19T21:58:27.103706Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# dice loss as defined above for 4 classes\ndef dice_coef(y_true, y_pred, smooth=1.0):\n    class_num = 4\n    for i in range(class_num):\n        y_true_f = K.flatten(y_true[:,:,:,i])\n        y_pred_f = K.flatten(y_pred[:,:,:,i])\n        intersection = K.sum(y_true_f * y_pred_f)\n        loss = ((2. * intersection + smooth) / (K.sum(y_true_f) + K.sum(y_pred_f) + smooth))\n   #     K.print_tensor(loss, message='loss value for class {} : '.format(SEGMENT_CLASSES[i]))\n        if i == 0:\n            total_loss = loss\n        else:\n            total_loss = total_loss + loss\n    total_loss = total_loss / class_num\n#    K.print_tensor(total_loss, message=' total dice coef: ')\n    return total_loss\n\n\n \n# define per class evaluation of dice coef\n# inspired by https://github.com/keras-team/keras/issues/9395\ndef dice_coef_necrotic(y_true, y_pred, epsilon=1e-6):\n    intersection = K.sum(K.abs(y_true[:,:,:,1] * y_pred[:,:,:,1]))\n    return (2. * intersection) / (K.sum(K.square(y_true[:,:,:,1])) + K.sum(K.square(y_pred[:,:,:,1])) + epsilon)\n\ndef dice_coef_edema(y_true, y_pred, epsilon=1e-6):\n    intersection = K.sum(K.abs(y_true[:,:,:,2] * y_pred[:,:,:,2]))\n    return (2. * intersection) / (K.sum(K.square(y_true[:,:,:,2])) + K.sum(K.square(y_pred[:,:,:,2])) + epsilon)\n\ndef dice_coef_enhancing(y_true, y_pred, epsilon=1e-6):\n    intersection = K.sum(K.abs(y_true[:,:,:,3] * y_pred[:,:,:,3]))\n    return (2. * intersection) / (K.sum(K.square(y_true[:,:,:,3])) + K.sum(K.square(y_pred[:,:,:,3])) + epsilon)\n\n\n\n# Computing Precision \ndef precision(y_true, y_pred):\n        true_positives = K.sum(K.round(K.clip(y_true * y_pred, 0, 1)))\n        predicted_positives = K.sum(K.round(K.clip(y_pred, 0, 1)))\n        precision = true_positives / (predicted_positives + K.epsilon())\n        return precision\n\n    \n# Computing Sensitivity      \ndef sensitivity(y_true, y_pred):\n    true_positives = K.sum(K.round(K.clip(y_true * y_pred, 0, 1)))\n    possible_positives = K.sum(K.round(K.clip(y_true, 0, 1)))\n    return true_positives / (possible_positives + K.epsilon())\n\n\n# Computing Specificity\ndef specificity(y_true, y_pred):\n    true_negatives = K.sum(K.round(K.clip((1-y_true) * (1-y_pred), 0, 1)))\n    possible_negatives = K.sum(K.round(K.clip(1-y_true, 0, 1)))\n    return true_negatives / (possible_negatives + K.epsilon())","metadata":{"execution":{"iopub.status.busy":"2024-07-19T21:58:27.10662Z","iopub.execute_input":"2024-07-19T21:58:27.107086Z","iopub.status.idle":"2024-07-19T21:58:27.135227Z","shell.execute_reply.started":"2024-07-19T21:58:27.107041Z","shell.execute_reply":"2024-07-19T21:58:27.134177Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"IMG_SIZE=128","metadata":{"execution":{"iopub.status.busy":"2024-07-19T21:58:27.136736Z","iopub.execute_input":"2024-07-19T21:58:27.137121Z","iopub.status.idle":"2024-07-19T21:58:27.151344Z","shell.execute_reply.started":"2024-07-19T21:58:27.137067Z","shell.execute_reply":"2024-07-19T21:58:27.150333Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# source https://naomi-fridman.medium.com/multi-class-image-segmentation-a5cc671e647a\n\ndef build_unet(inputs, ker_init, dropout):\n    conv1 = Conv2D(32, 3, activation = 'relu', padding = 'same', kernel_initializer = ker_init)(inputs)\n    conv1 = Conv2D(32, 3, activation = 'relu', padding = 'same', kernel_initializer = ker_init)(conv1)\n    \n    pool = MaxPooling2D(pool_size=(2, 2))(conv1)\n    conv = Conv2D(64, 3, activation = 'relu', padding = 'same', kernel_initializer = ker_init)(pool)\n    conv = Conv2D(64, 3, activation = 'relu', padding = 'same', kernel_initializer = ker_init)(conv)\n    \n    pool1 = MaxPooling2D(pool_size=(2, 2))(conv)\n    conv2 = Conv2D(128, 3, activation = 'relu', padding = 'same', kernel_initializer = ker_init)(pool1)\n    conv2 = Conv2D(128, 3, activation = 'relu', padding = 'same', kernel_initializer = ker_init)(conv2)\n    \n    pool2 = MaxPooling2D(pool_size=(2, 2))(conv2)\n    conv3 = Conv2D(256, 3, activation = 'relu', padding = 'same', kernel_initializer = ker_init)(pool2)\n    conv3 = Conv2D(256, 3, activation = 'relu', padding = 'same', kernel_initializer = ker_init)(conv3)\n    \n    \n    pool4 = MaxPooling2D(pool_size=(2, 2))(conv3)\n    conv5 = Conv2D(512, 3, activation = 'relu', padding = 'same', kernel_initializer = ker_init)(pool4)\n    conv5 = Conv2D(512, 3, activation = 'relu', padding = 'same', kernel_initializer = ker_init)(conv5)\n    drop5 = Dropout(dropout)(conv5)\n\n    up7 = Conv2D(256, 2, activation = 'relu', padding = 'same', kernel_initializer = ker_init)(UpSampling2D(size = (2,2))(drop5))\n    merge7 = concatenate([conv3,up7], axis = 3)\n    conv7 = Conv2D(256, 3, activation = 'relu', padding = 'same', kernel_initializer = ker_init)(merge7)\n    conv7 = Conv2D(256, 3, activation = 'relu', padding = 'same', kernel_initializer = ker_init)(conv7)\n\n    up8 = Conv2D(128, 2, activation = 'relu', padding = 'same', kernel_initializer = ker_init)(UpSampling2D(size = (2,2))(conv7))\n    merge8 = concatenate([conv2,up8], axis = 3)\n    conv8 = Conv2D(128, 3, activation = 'relu', padding = 'same', kernel_initializer = ker_init)(merge8)\n    conv8 = Conv2D(128, 3, activation = 'relu', padding = 'same', kernel_initializer = ker_init)(conv8)\n\n    up9 = Conv2D(64, 2, activation = 'relu', padding = 'same', kernel_initializer = ker_init)(UpSampling2D(size = (2,2))(conv8))\n    merge9 = concatenate([conv,up9], axis = 3)\n    conv9 = Conv2D(64, 3, activation = 'relu', padding = 'same', kernel_initializer = ker_init)(merge9)\n    conv9 = Conv2D(64, 3, activation = 'relu', padding = 'same', kernel_initializer = ker_init)(conv9)\n    \n    up = Conv2D(32, 2, activation = 'relu', padding = 'same', kernel_initializer = ker_init)(UpSampling2D(size = (2,2))(conv9))\n    merge = concatenate([conv1,up], axis = 3)\n    conv = Conv2D(32, 3, activation = 'relu', padding = 'same', kernel_initializer = ker_init)(merge)\n    conv = Conv2D(32, 3, activation = 'relu', padding = 'same', kernel_initializer = ker_init)(conv)\n    \n    conv10 = Conv2D(4, (1,1), activation = 'softmax')(conv)\n    \n    return Model(inputs = inputs, outputs = conv10)\n\ninput_layer = Input((IMG_SIZE, IMG_SIZE, 2))\n\nmodel = build_unet(input_layer, 'he_normal', 0.2)\nmodel.compile(loss=\"categorical_crossentropy\", optimizer=keras.optimizers.Adam(learning_rate=0.001), metrics = ['accuracy',tf.keras.metrics.MeanIoU(num_classes=4), dice_coef, precision, sensitivity, specificity, dice_coef_necrotic, dice_coef_edema ,dice_coef_enhancing] )","metadata":{"_kg_hide-input":true,"_kg_hide-output":true,"execution":{"iopub.status.busy":"2024-07-19T21:58:27.153167Z","iopub.execute_input":"2024-07-19T21:58:27.153643Z","iopub.status.idle":"2024-07-19T21:58:30.160929Z","shell.execute_reply.started":"2024-07-19T21:58:27.153598Z","shell.execute_reply":"2024-07-19T21:58:30.159901Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"plot_model(model, \n           show_shapes = True,\n           show_dtype=False,\n           show_layer_names = True, \n           rankdir = 'TB', \n           expand_nested = False, \n           dpi = 70)","metadata":{"execution":{"iopub.status.busy":"2024-07-19T21:58:30.162205Z","iopub.execute_input":"2024-07-19T21:58:30.162532Z","iopub.status.idle":"2024-07-19T21:58:30.967559Z","shell.execute_reply.started":"2024-07-19T21:58:30.1625Z","shell.execute_reply":"2024-07-19T21:58:30.966146Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# lists of directories with studies\ntrain_and_val_directories = [f.path for f in os.scandir(TRAIN_DATASET_PATH) if f.is_dir()]\n\n# file BraTS20_Training_355 has ill formatted name for for seg.nii file\ntrain_and_val_directories.remove(TRAIN_DATASET_PATH+'BraTS20_Training_355')\n\n\ndef pathListIntoIds(dirList):\n    x = []\n    for i in range(0,len(dirList)):\n        x.append(dirList[i][dirList[i].rfind('/')+1:])\n    return x\n\ntrain_and_test_ids = pathListIntoIds(train_and_val_directories); \n\n    \ntrain_test_ids, val_ids = train_test_split(train_and_test_ids,test_size=0.2) \ntrain_ids, test_ids = train_test_split(train_test_ids,test_size=0.15) ","metadata":{"_kg_hide-output":true,"_kg_hide-input":true,"execution":{"iopub.status.busy":"2024-07-19T21:58:30.969649Z","iopub.execute_input":"2024-07-19T21:58:30.970177Z","iopub.status.idle":"2024-07-19T21:58:31.011922Z","shell.execute_reply.started":"2024-07-19T21:58:30.970115Z","shell.execute_reply":"2024-07-19T21:58:31.010823Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"class DataGenerator(keras.utils.Sequence):\n    'Generates data for Keras'\n    def __init__(self, list_IDs, dim=(IMG_SIZE,IMG_SIZE), batch_size = 1, n_channels = 2, shuffle=True):\n        'Initialization'\n        self.dim = dim\n        self.batch_size = batch_size\n        self.list_IDs = list_IDs\n        self.n_channels = n_channels\n        self.shuffle = shuffle\n        self.on_epoch_end()\n\n    def __len__(self):\n        'Denotes the number of batches per epoch'\n        return int(np.floor(len(self.list_IDs) / self.batch_size))\n\n    def __getitem__(self, index):\n        'Generate one batch of data'\n        # Generate indexes of the batch\n        indexes = self.indexes[index*self.batch_size:(index+1)*self.batch_size]\n\n        # Find list of IDs\n        Batch_ids = [self.list_IDs[k] for k in indexes]\n\n        # Generate data\n        X, y = self.__data_generation(Batch_ids)\n\n        return X, y\n\n    def on_epoch_end(self):\n        'Updates indexes after each epoch'\n        self.indexes = np.arange(len(self.list_IDs))\n        if self.shuffle == True:\n            np.random.shuffle(self.indexes)\n\n    def __data_generation(self, Batch_ids):\n        'Generates data containing batch_size samples' # X : (n_samples, *dim, n_channels)\n        # Initialization\n        X = np.zeros((self.batch_size*VOLUME_SLICES, *self.dim, self.n_channels))\n        y = np.zeros((self.batch_size*VOLUME_SLICES, 240, 240))\n        Y = np.zeros((self.batch_size*VOLUME_SLICES, *self.dim, 4))\n\n        \n        # Generate data\n        for c, i in enumerate(Batch_ids):\n            case_path = os.path.join(TRAIN_DATASET_PATH, i)\n\n            data_path = os.path.join(case_path, f'{i}_flair.nii');\n            flair = nib.load(data_path).get_fdata()    \n\n            data_path = os.path.join(case_path, f'{i}_t1ce.nii');\n            ce = nib.load(data_path).get_fdata()\n            \n            data_path = os.path.join(case_path, f'{i}_seg.nii');\n            seg = nib.load(data_path).get_fdata()\n        \n            for j in range(VOLUME_SLICES):\n                 X[j +VOLUME_SLICES*c,:,:,0] = cv2.resize(flair[:,:,j+VOLUME_START_AT], (IMG_SIZE, IMG_SIZE));\n                 X[j +VOLUME_SLICES*c,:,:,1] = cv2.resize(ce[:,:,j+VOLUME_START_AT], (IMG_SIZE, IMG_SIZE));\n\n                 y[j +VOLUME_SLICES*c] = seg[:,:,j+VOLUME_START_AT];\n                    \n        # Generate masks\n        y[y==4] = 3;\n        mask = tf.one_hot(y, 4);\n        Y = tf.image.resize(mask, (IMG_SIZE, IMG_SIZE));\n        return X/np.max(X), Y\n        \ntraining_generator = DataGenerator(train_ids)\nvalid_generator = DataGenerator(val_ids)\ntest_generator = DataGenerator(test_ids)","metadata":{"_kg_hide-input":false,"_kg_hide-output":true,"execution":{"iopub.status.busy":"2024-07-19T21:58:31.013569Z","iopub.execute_input":"2024-07-19T21:58:31.013909Z","iopub.status.idle":"2024-07-19T21:58:31.036736Z","shell.execute_reply.started":"2024-07-19T21:58:31.013875Z","shell.execute_reply":"2024-07-19T21:58:31.035757Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# show number of data for each dir \ndef showDataLayout():\n    plt.bar([\"Train\",\"Valid\",\"Test\"],\n    [len(train_ids), len(val_ids), len(test_ids)], align='center',color=[ 'green','red', 'blue'])\n    plt.legend()\n\n    plt.ylabel('Number of images')\n    plt.title('Data distribution')\n\n    plt.show()\n    \nshowDataLayout()","metadata":{"_kg_hide-input":true,"execution":{"iopub.status.busy":"2024-07-19T21:58:31.038378Z","iopub.execute_input":"2024-07-19T21:58:31.038832Z","iopub.status.idle":"2024-07-19T21:58:31.205432Z","shell.execute_reply.started":"2024-07-19T21:58:31.038795Z","shell.execute_reply":"2024-07-19T21:58:31.204525Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"csv_logger = CSVLogger('training.log', separator=',', append=False)\n\n\ncallbacks = [\n#     keras.callbacks.EarlyStopping(monitor='loss', min_delta=0,\n#                               patience=2, verbose=1, mode='auto'),\n      keras.callbacks.ReduceLROnPlateau(monitor='val_loss', factor=0.2,\n                              patience=2, min_lr=0.000001, verbose=1),\n#  keras.callbacks.ModelCheckpoint(filepath = 'model_.{epoch:02d}-{val_loss:.6f}.m5',\n#                             verbose=1, save_best_only=True, save_weights_only = True)\n        csv_logger\n    ]","metadata":{"_kg_hide-input":true,"execution":{"iopub.status.busy":"2024-07-19T21:58:31.206716Z","iopub.execute_input":"2024-07-19T21:58:31.207019Z","iopub.status.idle":"2024-07-19T21:58:31.212727Z","shell.execute_reply.started":"2024-07-19T21:58:31.20699Z","shell.execute_reply":"2024-07-19T21:58:31.211733Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"K.clear_session()\n# I train by 35 epochs but for time i will use 15 epochs\nhistory =  model.fit(training_generator,\n                    epochs=15,\n                     steps_per_epoch=len(train_ids),\n                     callbacks= callbacks,\n                     validation_data = valid_generator\n                     )  \nmodel.save(\"3D_MRI_Brain_tumor_segmentation.h5\")","metadata":{"execution":{"iopub.status.busy":"2024-07-19T21:58:31.216472Z","iopub.execute_input":"2024-07-19T21:58:31.217015Z","iopub.status.idle":"2024-07-19T22:27:51.570796Z","shell.execute_reply.started":"2024-07-19T21:58:31.216923Z","shell.execute_reply":"2024-07-19T22:27:51.569783Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import tensorflow as tf\nimport numpy as np\nimport nibabel as nib\nimport cv2\n\n# Load the saved model\nmodel = tf.keras.models.load_model(\"3D_MRI_Brain_tumor_segmentation.h5\", custom_objects={\n    'dice_coef': dice_coef,\n    'precision': precision,\n    'sensitivity': sensitivity,\n    'specificity': specificity,\n    'dice_coef_necrotic': dice_coef_necrotic,\n    'dice_coef_edema': dice_coef_edema,\n    'dice_coef_enhancing': dice_coef_enhancing\n})\n\ndef preprocess_image(image_file, slice_index=None):\n    # Load the NIfTI file\n    img = nib.load(image_file).get_fdata()\n    \n    # Select a specific slice if needed\n    if slice_index is not None:\n        img = img[:, :, slice_index]\n    \n    # Resize the image to (IMG_SIZE, IMG_SIZE)\n    img_resized = cv2.resize(img, (IMG_SIZE, IMG_SIZE))\n    \n    # Normalize the image\n    img_resized = img_resized / np.max(img_resized)\n    \n    return img_resized\n\ndef predict(image_paths, slice_index):\n    X = np.zeros((1, IMG_SIZE, IMG_SIZE, 2))\n    \n    # Process specific slices from the images\n    X[0, :, :, 0] = preprocess_image(image_paths[0], slice_index)\n    X[0, :, :, 1] = preprocess_image(image_paths[1], slice_index)\n    \n    # Make prediction\n    pred = model.predict(X)\n    \n    return np.argmax(pred[0], axis=-1)\n\n# Example usage\nimage_paths = [\n    '/kaggle/input/brats20-dataset-training-validation/BraTS2020_ValidationData/MICCAI_BraTS2020_ValidationData/BraTS20_Validation_010/BraTS20_Validation_010_flair.nii',\n    '/kaggle/input/brats20-dataset-training-validation/BraTS2020_ValidationData/MICCAI_BraTS2020_ValidationData/BraTS20_Validation_010/BraTS20_Validation_010_t1ce.nii'\n]\n\nslice_index = 75  # Example slice index\nprediction = predict(image_paths, slice_index)\n","metadata":{"execution":{"iopub.status.busy":"2024-07-19T22:44:52.191454Z","iopub.execute_input":"2024-07-19T22:44:52.191886Z","iopub.status.idle":"2024-07-19T22:44:53.922897Z","shell.execute_reply.started":"2024-07-19T22:44:52.19185Z","shell.execute_reply":"2024-07-19T22:44:53.921805Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import numpy as np\n\ndef get_classification(pred):\n    # Get the class with the highest probability for each pixel\n    class_predictions = np.argmax(pred, axis=-1)\n    return class_predictions\n","metadata":{"execution":{"iopub.status.busy":"2024-07-19T22:45:00.943899Z","iopub.execute_input":"2024-07-19T22:45:00.944285Z","iopub.status.idle":"2024-07-19T22:45:00.95007Z","shell.execute_reply.started":"2024-07-19T22:45:00.944253Z","shell.execute_reply":"2024-07-19T22:45:00.948641Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"get_classification(prediction)","metadata":{"execution":{"iopub.status.busy":"2024-07-19T22:45:02.110767Z","iopub.execute_input":"2024-07-19T22:45:02.11116Z","iopub.status.idle":"2024-07-19T22:45:02.118055Z","shell.execute_reply.started":"2024-07-19T22:45:02.111122Z","shell.execute_reply":"2024-07-19T22:45:02.117091Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import matplotlib.pyplot as plt\n\ndef visualize_prediction(prediction):\n    plt.imshow(prediction, cmap='nipy_spectral')  # 'nipy_spectral' gives distinct colors for different classes\n    plt.title('Predicted Segmentation')\n    plt.colorbar()\n    plt.show()\n","metadata":{"execution":{"iopub.status.busy":"2024-07-19T22:45:04.715951Z","iopub.execute_input":"2024-07-19T22:45:04.716359Z","iopub.status.idle":"2024-07-19T22:45:04.722431Z","shell.execute_reply.started":"2024-07-19T22:45:04.716324Z","shell.execute_reply":"2024-07-19T22:45:04.721082Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"visualize_prediction(prediction)","metadata":{"execution":{"iopub.status.busy":"2024-07-19T22:45:06.191181Z","iopub.execute_input":"2024-07-19T22:45:06.191602Z","iopub.status.idle":"2024-07-19T22:45:06.768009Z","shell.execute_reply.started":"2024-07-19T22:45:06.191568Z","shell.execute_reply":"2024-07-19T22:45:06.766977Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"############ load trained model ################\nmodel = keras.models.load_model('../input/modelperclasseval/model_per_class.h5', \n                                   custom_objects={ 'accuracy' : tf.keras.metrics.MeanIoU(num_classes=4),\n                                                   \"dice_coef\": dice_coef,\n                                                   \"precision\": precision,\n                                                   \"sensitivity\":sensitivity,\n                                                   \"specificity\":specificity,\n                                                   \"dice_coef_necrotic\": dice_coef_necrotic,\n                                                   \"dice_coef_edema\": dice_coef_edema,\n                                                   \"dice_coef_enhancing\": dice_coef_enhancing\n                                                  }, compile=False)\n\nhistory = pd.read_csv('../input/modelperclasseval/training_per_class.log', sep=',', engine='python')\n\nhist=history\n\n############### ########## ####### #######\n\n# hist=history.history\n\nacc=hist['accuracy']\nval_acc=hist['val_accuracy']\n\nepoch=range(len(acc))\n\nloss=hist['loss']\nval_loss=hist['val_loss']\n\ntrain_dice=hist['dice_coef']\nval_dice=hist['val_dice_coef']\n\nf,ax=plt.subplots(1,4,figsize=(16,8))\n\nax[0].plot(epoch,acc,'b',label='Training Accuracy')\nax[0].plot(epoch,val_acc,'r',label='Validation Accuracy')\nax[0].legend()\n\nax[1].plot(epoch,loss,'b',label='Training Loss')\nax[1].plot(epoch,val_loss,'r',label='Validation Loss')\nax[1].legend()\n\nax[2].plot(epoch,train_dice,'b',label='Training dice coef')\nax[2].plot(epoch,val_dice,'r',label='Validation dice coef')\nax[2].legend()\n\nax[3].plot(epoch,hist['mean_io_u'],'b',label='Training mean IOU')\nax[3].plot(epoch,hist['val_mean_io_u'],'r',label='Validation mean IOU')\nax[3].legend()\n\nplt.show()","metadata":{"execution":{"iopub.status.busy":"2024-07-19T22:45:11.1017Z","iopub.execute_input":"2024-07-19T22:45:11.102085Z","iopub.status.idle":"2024-07-19T22:45:12.753122Z","shell.execute_reply.started":"2024-07-19T22:45:11.102053Z","shell.execute_reply":"2024-07-19T22:45:12.752055Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# mri type must one of 1) flair 2) t1 3) t1ce 4) t2 ------- or even 5) seg\n# returns volume of specified study at `path`\ndef imageLoader(path):\n    image = nib.load(path).get_fdata()\n    X = np.zeros((self.batch_size*VOLUME_SLICES, *self.dim, self.n_channels))\n    for j in range(VOLUME_SLICES):\n        X[j +VOLUME_SLICES*c,:,:,0] = cv2.resize(image[:,:,j+VOLUME_START_AT], (IMG_SIZE, IMG_SIZE));\n        X[j +VOLUME_SLICES*c,:,:,1] = cv2.resize(ce[:,:,j+VOLUME_START_AT], (IMG_SIZE, IMG_SIZE));\n\n        y[j +VOLUME_SLICES*c] = seg[:,:,j+VOLUME_START_AT];\n    return np.array(image)\n\n\n# load nifti file at `path`\n# and load each slice with mask from volume\n# choose the mri type & resize to `IMG_SIZE`\ndef loadDataFromDir(path, list_of_files, mriType, n_images):\n    scans = []\n    masks = []\n    for i in list_of_files[:n_images]:\n        fullPath = glob.glob( i + '/*'+ mriType +'*')[0]\n        currentScanVolume = imageLoader(fullPath)\n        currentMaskVolume = imageLoader( glob.glob( i + '/*seg*')[0] ) \n        # for each slice in 3D volume, find also it's mask\n        for j in range(0, currentScanVolume.shape[2]):\n            scan_img = cv2.resize(currentScanVolume[:,:,j], dsize=(IMG_SIZE,IMG_SIZE), interpolation=cv2.INTER_AREA).astype('uint8')\n            mask_img = cv2.resize(currentMaskVolume[:,:,j], dsize=(IMG_SIZE,IMG_SIZE), interpolation=cv2.INTER_AREA).astype('uint8')\n            scans.append(scan_img[..., np.newaxis])\n            masks.append(mask_img[..., np.newaxis])\n    return np.array(scans, dtype='float32'), np.array(masks, dtype='float32')\n        \n#brains_list_test, masks_list_test = loadDataFromDir(VALIDATION_DATASET_PATH, test_directories, \"flair\", 5)\n","metadata":{"_kg_hide-input":true,"_kg_hide-output":true,"execution":{"iopub.status.busy":"2024-07-19T22:45:26.256316Z","iopub.execute_input":"2024-07-19T22:45:26.256762Z","iopub.status.idle":"2024-07-19T22:45:26.277216Z","shell.execute_reply.started":"2024-07-19T22:45:26.256719Z","shell.execute_reply":"2024-07-19T22:45:26.275823Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def predictByPath(case_path,case):\n    files = next(os.walk(case_path))[2]\n    X = np.empty((VOLUME_SLICES, IMG_SIZE, IMG_SIZE, 2))\n  #  y = np.empty((VOLUME_SLICES, IMG_SIZE, IMG_SIZE))\n    \n    vol_path = os.path.join(case_path, f'BraTS20_Training_{case}_flair.nii');\n    flair=nib.load(vol_path).get_fdata()\n    \n    vol_path = os.path.join(case_path, f'BraTS20_Training_{case}_t1ce.nii');\n    ce=nib.load(vol_path).get_fdata() \n    \n #   vol_path = os.path.join(case_path, f'BraTS20_Training_{case}_seg.nii');\n #   seg=nib.load(vol_path).get_fdata()  \n\n    \n    for j in range(VOLUME_SLICES):\n        X[j,:,:,0] = cv2.resize(flair[:,:,j+VOLUME_START_AT], (IMG_SIZE,IMG_SIZE))\n        X[j,:,:,1] = cv2.resize(ce[:,:,j+VOLUME_START_AT], (IMG_SIZE,IMG_SIZE))\n #       y[j,:,:] = cv2.resize(seg[:,:,j+VOLUME_START_AT], (IMG_SIZE,IMG_SIZE))\n        \n  #  model.evaluate(x=X,y=y[:,:,:,0], callbacks= callbacks)\n    return model.predict(X/np.max(X), verbose=1)\n\n\ndef showPredictsById(case, start_slice = 60):\n    path = f\"../input/brats20-dataset-training-validation/BraTS2020_TrainingData/MICCAI_BraTS2020_TrainingData/BraTS20_Training_{case}\"\n    gt = nib.load(os.path.join(path, f'BraTS20_Training_{case}_seg.nii')).get_fdata()\n    origImage = nib.load(os.path.join(path, f'BraTS20_Training_{case}_flair.nii')).get_fdata()\n    p = predictByPath(path,case)\n\n    core = p[:,:,:,1]\n    edema= p[:,:,:,2]\n    enhancing = p[:,:,:,3]\n\n    plt.figure(figsize=(18, 50))\n    f, axarr = plt.subplots(1,6, figsize = (18, 50)) \n\n    for i in range(6): # for each image, add brain background\n        axarr[i].imshow(cv2.resize(origImage[:,:,start_slice+VOLUME_START_AT], (IMG_SIZE, IMG_SIZE)), cmap=\"gray\", interpolation='none')\n    \n    axarr[0].imshow(cv2.resize(origImage[:,:,start_slice+VOLUME_START_AT], (IMG_SIZE, IMG_SIZE)), cmap=\"gray\")\n    axarr[0].title.set_text('Original image flair')\n    curr_gt=cv2.resize(gt[:,:,start_slice+VOLUME_START_AT], (IMG_SIZE, IMG_SIZE), interpolation = cv2.INTER_NEAREST)\n    axarr[1].imshow(curr_gt, cmap=\"Reds\", interpolation='none', alpha=0.3) # ,alpha=0.3,cmap='Reds'\n    axarr[1].title.set_text('Ground truth')\n    axarr[2].imshow(p[start_slice,:,:,1:4], cmap=\"Reds\", interpolation='none', alpha=0.3)\n    axarr[2].title.set_text('all classes')\n    axarr[3].imshow(edema[start_slice,:,:], cmap=\"OrRd\", interpolation='none', alpha=0.3)\n    axarr[3].title.set_text(f'{SEGMENT_CLASSES[1]} predicted')\n    axarr[4].imshow(core[start_slice,:,], cmap=\"OrRd\", interpolation='none', alpha=0.3)\n    axarr[4].title.set_text(f'{SEGMENT_CLASSES[2]} predicted')\n    axarr[5].imshow(enhancing[start_slice,:,], cmap=\"OrRd\", interpolation='none', alpha=0.3)\n    axarr[5].title.set_text(f'{SEGMENT_CLASSES[3]} predicted')\n    plt.show()\n    \n    \nshowPredictsById(case=test_ids[0][-3:])\nshowPredictsById(case=test_ids[1][-3:])\nshowPredictsById(case=test_ids[2][-3:])\nshowPredictsById(case=test_ids[3][-3:])\nshowPredictsById(case=test_ids[4][-3:])\nshowPredictsById(case=test_ids[5][-3:])\nshowPredictsById(case=test_ids[6][-3:])\n\n\n# mask = np.zeros((10,10))\n# mask[3:-3, 3:-3] = 1 # white square in black background\n# im = mask + np.random.randn(10,10) * 0.01 # random image\n# masked = np.ma.masked_where(mask == 0, mask)\n\n# plt.figure()\n# plt.subplot(1,2,1)\n# plt.imshow(im, 'gray', interpolation='none')\n# plt.subplot(1,2,2)\n# plt.imshow(im, 'gray', interpolation='none')\n# plt.imshow(masked, 'jet', interpolation='none', alpha=0.7)\n# plt.show()","metadata":{"execution":{"iopub.status.busy":"2024-07-19T22:45:27.245394Z","iopub.execute_input":"2024-07-19T22:45:27.245847Z","iopub.status.idle":"2024-07-19T22:45:39.444453Z","shell.execute_reply.started":"2024-07-19T22:45:27.245803Z","shell.execute_reply":"2024-07-19T22:45:39.443257Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"fig, ax1 = plt.subplots(1, 1, figsize = (15,15))\nax1.imshow(rotate(montage(test_image_t1[50:-50,:,:]), 90, resize=True), cmap ='gray')","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"case = case=test_ids[3][-3:]\npath = f\"../input/brats20-dataset-training-validation/BraTS2020_TrainingData/MICCAI_BraTS2020_TrainingData/BraTS20_Training_{case}\"\ngt = nib.load(os.path.join(path, f'BraTS20_Training_{case}_seg.nii')).get_fdata()\np = predictByPath(path,case)\n\n\ncore = p[:,:,:,1]\nedema= p[:,:,:,2]\nenhancing = p[:,:,:,3]\n\n\ni=40 # slice at\neval_class = 2 #     0 : 'NOT tumor',  1 : 'ENHANCING',    2 : 'CORE',    3 : 'WHOLE'\n\n\n\ngt[gt != eval_class] = 1 # use only one class for per class evaluation \n\nresized_gt = cv2.resize(gt[:,:,i+VOLUME_START_AT], (IMG_SIZE, IMG_SIZE))\n\nplt.figure()\nf, axarr = plt.subplots(1,2) \naxarr[0].imshow(resized_gt, cmap=\"gray\")\naxarr[0].title.set_text('ground truth')\naxarr[1].imshow(p[i,:,:,eval_class], cmap=\"gray\")\naxarr[1].title.set_text(f'predicted class: {SEGMENT_CLASSES[eval_class]}')\nplt.show()","metadata":{"_kg_hide-input":true,"_kg_hide-output":false,"execution":{"iopub.status.busy":"2024-07-19T22:45:39.446677Z","iopub.execute_input":"2024-07-19T22:45:39.44714Z","iopub.status.idle":"2024-07-19T22:45:40.204585Z","shell.execute_reply.started":"2024-07-19T22:45:39.447093Z","shell.execute_reply":"2024-07-19T22:45:40.203715Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"model.compile(loss=\"categorical_crossentropy\", optimizer=keras.optimizers.Adam(learning_rate=0.001), metrics = ['accuracy',tf.keras.metrics.MeanIoU(num_classes=4), dice_coef, precision, sensitivity, specificity, dice_coef_necrotic, dice_coef_edema, dice_coef_enhancing] )\n# Evaluate the model on the test data using `evaluate`\nprint(\"Evaluate on test data\")\nresults = model.evaluate(test_generator, batch_size=100, callbacks= callbacks)\nprint(\"test loss, test acc:\", results)","metadata":{"_kg_hide-input":false,"_kg_hide-output":true,"execution":{"iopub.status.busy":"2024-07-19T22:45:40.205999Z","iopub.execute_input":"2024-07-19T22:45:40.20631Z","iopub.status.idle":"2024-07-19T22:46:08.43662Z","shell.execute_reply.started":"2024-07-19T22:45:40.20628Z","shell.execute_reply":"2024-07-19T22:46:08.435637Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]}]}